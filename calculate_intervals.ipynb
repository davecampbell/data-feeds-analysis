{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'logging' from '/usr/local/anaconda3/lib/python3.6/logging/__init__.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from datetime import timedelta\n",
    "import time\n",
    "import dateutil\n",
    "from dateutil.parser import parse\n",
    "import logging\n",
    "import importlib\n",
    "importlib.reload(logging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s %(levelname)s:%(message)s', level=logging.DEBUG, datefmt='%I:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10:30:08 INFO:now starting...\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"now starting...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10:30:08 INFO:...before reading csv file.\n",
      "10:30:20 INFO:...after reading csv file.\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"...before reading csv file.\")\n",
    "# read a csv into a dataframe\n",
    "df = pd.read_csv('data/IMPORT_CONTROL.txt')\n",
    "logging.info(\"...after reading csv file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10:30:20 INFO:...before creating new column.\n",
      "10:30:29 INFO:...after creating new column.\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"...before creating new column.\")\n",
    "# need to make a field to uniquely identify each agency\n",
    "# concatenating the SITE_ID and the AGENCY will do this\n",
    "named = df.assign(uniquename = df.SITE_ID.astype(str) + '-' + df.AGENCY.astype(str))\n",
    "logging.info(\"...after creating new column.\")\n",
    "\n",
    "# new dataframe to record new info\n",
    "# interval_df = pd.DataFrame(columns=['uniquename', 'timestamp', 'interval', 'origindex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10:30:29 INFO:...before groupby.\n",
      "10:30:30 INFO:...after groupby.\n"
     ]
    }
   ],
   "source": [
    "# use the groupby functions to look at events for each agency\n",
    "logging.info(\"...before groupby.\")\n",
    "grouped = named.groupby('uniquename')\n",
    "logging.info(\"...after groupby.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10:30:30 INFO:...before dict\n",
      "10:30:38 INFO:...after dict\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"...before dict\")\n",
    "# make a dictionary of the group names\n",
    "groups = dict(list(grouped))\n",
    "logging.info(\"...after dict\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10:30:39 INFO:agency #1 out of 2361\n",
      "10:30:58 INFO:agency #20 out of 2361\n",
      "10:31:21 INFO:agency #40 out of 2361\n",
      "10:31:57 INFO:agency #60 out of 2361\n",
      "10:32:29 INFO:agency #80 out of 2361\n",
      "10:33:50 INFO:agency #100 out of 2361\n",
      "10:34:26 INFO:agency #120 out of 2361\n",
      "10:34:40 INFO:agency #140 out of 2361\n",
      "10:34:52 INFO:agency #160 out of 2361\n",
      "10:34:58 INFO:agency #180 out of 2361\n",
      "10:35:08 INFO:agency #200 out of 2361\n",
      "10:35:16 INFO:agency #220 out of 2361\n",
      "10:35:27 INFO:agency #240 out of 2361\n",
      "10:35:40 INFO:agency #260 out of 2361\n",
      "10:35:45 INFO:agency #280 out of 2361\n",
      "10:35:58 INFO:agency #300 out of 2361\n",
      "10:36:11 INFO:agency #320 out of 2361\n",
      "10:36:31 INFO:agency #340 out of 2361\n",
      "10:36:54 INFO:agency #360 out of 2361\n",
      "10:37:14 INFO:agency #380 out of 2361\n",
      "10:37:27 INFO:agency #400 out of 2361\n",
      "10:37:37 INFO:agency #420 out of 2361\n",
      "10:37:46 INFO:agency #440 out of 2361\n",
      "10:37:55 INFO:agency #460 out of 2361\n",
      "10:38:05 INFO:agency #480 out of 2361\n",
      "10:38:23 INFO:agency #500 out of 2361\n",
      "10:38:35 INFO:agency #520 out of 2361\n",
      "10:38:45 INFO:agency #540 out of 2361\n",
      "10:38:57 INFO:agency #560 out of 2361\n",
      "10:39:16 INFO:agency #580 out of 2361\n",
      "10:39:36 INFO:agency #600 out of 2361\n",
      "10:39:55 INFO:agency #620 out of 2361\n",
      "10:40:22 INFO:agency #640 out of 2361\n",
      "10:40:45 INFO:agency #660 out of 2361\n",
      "10:40:58 INFO:agency #680 out of 2361\n",
      "10:41:13 INFO:agency #700 out of 2361\n",
      "10:41:17 INFO:agency #720 out of 2361\n",
      "10:41:21 INFO:agency #740 out of 2361\n",
      "10:41:21 INFO:agency #760 out of 2361\n",
      "10:41:29 INFO:agency #780 out of 2361\n",
      "10:41:47 INFO:agency #800 out of 2361\n",
      "10:42:07 INFO:agency #820 out of 2361\n",
      "10:42:22 INFO:agency #840 out of 2361\n",
      "10:42:28 INFO:agency #860 out of 2361\n",
      "10:42:47 INFO:agency #880 out of 2361\n",
      "10:43:00 INFO:agency #900 out of 2361\n",
      "10:43:19 INFO:agency #920 out of 2361\n",
      "10:43:31 INFO:agency #940 out of 2361\n",
      "10:43:47 INFO:agency #960 out of 2361\n",
      "10:44:01 INFO:agency #980 out of 2361\n",
      "10:44:10 INFO:agency #1000 out of 2361\n",
      "10:44:33 INFO:agency #1020 out of 2361\n",
      "10:44:37 INFO:agency #1040 out of 2361\n",
      "10:44:39 INFO:agency #1060 out of 2361\n",
      "10:44:40 INFO:agency #1080 out of 2361\n",
      "10:44:41 INFO:agency #1100 out of 2361\n",
      "10:44:42 INFO:agency #1120 out of 2361\n",
      "10:44:45 INFO:agency #1140 out of 2361\n",
      "10:44:56 INFO:agency #1160 out of 2361\n",
      "10:45:09 INFO:agency #1180 out of 2361\n",
      "10:45:21 INFO:agency #1200 out of 2361\n",
      "10:45:28 INFO:agency #1220 out of 2361\n",
      "10:45:33 INFO:agency #1240 out of 2361\n",
      "10:45:50 INFO:agency #1260 out of 2361\n",
      "10:46:11 INFO:agency #1280 out of 2361\n",
      "10:46:29 INFO:agency #1300 out of 2361\n",
      "10:46:47 INFO:agency #1320 out of 2361\n",
      "10:47:08 INFO:agency #1340 out of 2361\n",
      "10:47:26 INFO:agency #1360 out of 2361\n",
      "10:47:46 INFO:agency #1380 out of 2361\n",
      "10:48:06 INFO:agency #1400 out of 2361\n",
      "10:48:21 INFO:agency #1420 out of 2361\n",
      "10:48:40 INFO:agency #1440 out of 2361\n",
      "10:49:07 INFO:agency #1460 out of 2361\n",
      "10:49:27 INFO:agency #1480 out of 2361\n",
      "10:49:49 INFO:agency #1500 out of 2361\n",
      "10:49:59 INFO:agency #1520 out of 2361\n",
      "10:50:03 INFO:agency #1540 out of 2361\n",
      "10:50:14 INFO:agency #1560 out of 2361\n",
      "10:50:27 INFO:agency #1580 out of 2361\n",
      "10:51:00 INFO:agency #1600 out of 2361\n",
      "10:51:20 INFO:agency #1620 out of 2361\n",
      "10:51:41 INFO:agency #1640 out of 2361\n",
      "10:52:00 INFO:agency #1660 out of 2361\n",
      "10:52:19 INFO:agency #1680 out of 2361\n",
      "10:52:43 INFO:agency #1700 out of 2361\n",
      "10:53:06 INFO:agency #1720 out of 2361\n",
      "10:53:27 INFO:agency #1740 out of 2361\n",
      "10:53:50 INFO:agency #1760 out of 2361\n",
      "10:54:06 INFO:agency #1780 out of 2361\n",
      "10:54:21 INFO:agency #1800 out of 2361\n",
      "10:54:42 INFO:agency #1820 out of 2361\n",
      "10:54:50 INFO:agency #1840 out of 2361\n",
      "10:54:56 INFO:agency #1860 out of 2361\n",
      "10:55:07 INFO:agency #1880 out of 2361\n",
      "10:55:29 INFO:agency #1900 out of 2361\n",
      "10:55:52 INFO:agency #1920 out of 2361\n",
      "10:56:12 INFO:agency #1940 out of 2361\n",
      "10:56:36 INFO:agency #1960 out of 2361\n",
      "10:56:53 INFO:agency #1980 out of 2361\n",
      "10:57:14 INFO:agency #2000 out of 2361\n",
      "10:57:47 INFO:agency #2020 out of 2361\n",
      "10:58:24 INFO:agency #2040 out of 2361\n",
      "10:58:34 INFO:agency #2060 out of 2361\n",
      "10:58:46 INFO:agency #2080 out of 2361\n",
      "10:59:05 INFO:agency #2100 out of 2361\n",
      "10:59:06 INFO:agency #2120 out of 2361\n",
      "10:59:08 INFO:agency #2140 out of 2361\n",
      "10:59:09 INFO:agency #2160 out of 2361\n",
      "10:59:11 INFO:agency #2180 out of 2361\n",
      "10:59:13 INFO:agency #2200 out of 2361\n",
      "10:59:27 INFO:agency #2220 out of 2361\n",
      "10:59:53 INFO:agency #2240 out of 2361\n",
      "11:00:14 INFO:agency #2260 out of 2361\n",
      "11:00:33 INFO:agency #2280 out of 2361\n",
      "11:00:44 INFO:agency #2300 out of 2361\n",
      "11:01:04 INFO:agency #2320 out of 2361\n",
      "11:01:22 INFO:agency #2340 out of 2361\n",
      "11:01:47 INFO:agency #2360 out of 2361\n"
     ]
    }
   ],
   "source": [
    "data_rows = []\n",
    "i = 0\n",
    "# for each group\n",
    "for name in groups:\n",
    "    # print(name)\n",
    "    # get the group as a dataframe\n",
    "    g = grouped.get_group(name)\n",
    "    # logging.info(\"length of group: {}\".format(len(g)))\n",
    "    j = 0\n",
    "    t = time.process_time()\n",
    "    # then go through the dataframe row by row\n",
    "    for r in g.itertuples():\n",
    "        # logging.info(\"..on row# {}\".format(r))\n",
    "        # only for rows > 0\n",
    "        row = {}\n",
    "        if j > 0 and isinstance(r.PROCESS_END_TS, str):\n",
    "            # calculate seconds between this timestamp and the timestamp from the last row\n",
    "            thistime = parse(r.PROCESS_END_TS)\n",
    "            lasttime = parse(last)\n",
    "            secs = (thistime - lasttime).total_seconds()\n",
    "            # print(r.Index, thistime, lasttime, secs)\n",
    "            # interval_df = interval_df.append({'timestamp': thistime, 'uniquename': name, 'interval': secs, 'origindex': r.Index}, ignore_index=True)\n",
    "            # set the dictionary with the values from this calculated interval\n",
    "            row['timestamp'] = thistime\n",
    "            row['uniquename'] = name\n",
    "            row['interval'] = secs\n",
    "            row['origindex'] = r.Index\n",
    "            last = r.PROCESS_END_TS\n",
    "        if j == 0 and isinstance(r.PROCESS_END_TS, str):\n",
    "            last = r.PROCESS_END_TS\n",
    "        j += 1\n",
    "        # append the dictionary to the data_rows array\n",
    "        data_rows.append(row)\n",
    "    i += 1\n",
    "    dur = time.process_time() - t\n",
    "#    logging.info(\"dur: {}, num: {}, avg: {}\".format(dur, len(g), dur / len(g)))\n",
    "    if i > 200000:\n",
    "        break\n",
    "    if i == 1 or i%20 == 0:\n",
    "        logging.info(\"agency #{} out of {}\".format(i, len(groups)))\n",
    "\n",
    "# create the dataframe from the data_rows array\n",
    "interval_df = pd.DataFrame(data_rows)\n",
    "# then write it out to a file\n",
    "interval_df.to_csv('data/intervals.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
