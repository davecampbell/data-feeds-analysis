{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'logging' from '/anaconda3/lib/python3.7/logging/__init__.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from datetime import timedelta\n",
    "import dateutil\n",
    "from dateutil.parser import parse\n",
    "import logging\n",
    "import importlib\n",
    "importlib.reload(logging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s %(levelname)s:%(message)s', level=logging.DEBUG, datefmt='%I:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06:09:02 INFO:starting...\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"starting...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06:09:04 INFO:...before reading csv file.\n",
      "06:09:14 INFO:...after reading csv file.\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"...before reading csv file.\")\n",
    "# read a csv into a dataframe\n",
    "df = pd.read_csv('data/IMPORT_CONTROL.txt')\n",
    "logging.info(\"...after reading csv file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06:09:14 INFO:...before creating new column.\n",
      "06:09:22 INFO:...after creating new column.\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"...before creating new column.\")\n",
    "# need to make a field to uniquely identify each agency\n",
    "# concatenating the SITE_ID and the AGENCY will do this\n",
    "named = df.assign(uniquename = df.SITE_ID.astype(str) + '-' + df.AGENCY.astype(str))\n",
    "logging.info(\"...after creating new column.\")\n",
    "\n",
    "# new dataframe to record new info\n",
    "interval_df = pd.DataFrame(columns=['uniquename', 'timestamp', 'interval', 'origindex'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06:09:41 INFO:...before groupby.\n",
      "06:09:43 INFO:...after groupby.\n"
     ]
    }
   ],
   "source": [
    "# use the groupby functions to look at events for each agency\n",
    "logging.info(\"...before groupby.\")\n",
    "grouped = named.groupby('uniquename')\n",
    "logging.info(\"...after groupby.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06:09:49 INFO:...before dict\n",
      "06:09:55 INFO:...after dict\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"...before dict\")\n",
    "# make a dictionary of the group names\n",
    "groups = dict(list(grouped))\n",
    "logging.info(\"...after dict\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "# for each group\n",
    "for name in groups:\n",
    "    # print(name)\n",
    "    # get the group as a dataframe\n",
    "    logging.info(\"...before get_group({})\".format(name))\n",
    "    g = grouped.get_group(name)\n",
    "    logging.info(\"...after get_group({})\".format(name))\n",
    "    logging.info(\"length of group: {}\".format(len(g)))\n",
    "    j = 0\n",
    "    # then go through the dataframe row by row\n",
    "    for r in g.itertuples():\n",
    "        logging.info(\"..on row# {}\".format(r))\n",
    "        # only for rows > 0\n",
    "        if j > 0 and isinstance(r.PROCESS_END_TS, basestring):\n",
    "            # calculate seconds between this timestamp and the timestamp from the last row\n",
    "            thistime = parse(r.PROCESS_END_TS)\n",
    "            lasttime = parse(last)\n",
    "            secs = (thistime - lasttime).total_seconds()\n",
    "            # print(r.Index, thistime, lasttime, secs)\n",
    "            interval_df = interval_df.append({'timestamp': thistime, 'uniquename': name, 'interval': secs, 'origindex': r.Index}, ignore_index=True)\n",
    "            last = r.PROCESS_END_TS\n",
    "        if j == 0 and isinstance(r.PROCESS_END_TS, basestring):\n",
    "            last = r.PROCESS_END_TS\n",
    "        j += 1\n",
    "    i += 1\n",
    "    if i > 200000:\n",
    "        break\n",
    "    if i == 1 or i%50 == 0:\n",
    "        logging.info(\"agency #{} out of {}\".format(i, len(groups)))\n",
    "        \n",
    "\n",
    "interval_df.to_csv('intervals.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
